{
  "_descriptorVersion": "0.0.1",
  "datePublished": "2023-08-07T21:51:07",
  "name": "Vicuna 13B v1.5 16K",
  "description": "Vicuna is a state-of-the-art chat assistant developed by LMSYS, leveraging the transformative power of an auto-regressive language model based on the transformer architecture. Trained via fine-tuning the Llama 2 model, Vicuna is used primarily for research in large language models and chatbots, catering to the needs of AI enthusiasts, machine learning researchers, and hobbyists. The model operates under the Llama 2 Community License Agreement. The latest version, Vicuna v1.5 (16k), has been fine-tuned using supervised instruction and linear RoPE scaling, with training data comprising around 125K conversations collected from ShareGPT.com, packed into sequences of 16K tokens each. A comprehensive explanation of the training details can be found in the appendix to the linked paper titled \"Training Details of Vicuna Models.\"",
  "author": {
    "name": "LMSYS Org",
    "url": "https://lmsys.org/",
    "blurb": "Large Model Systems Organization (LMSYS Org) is an open research organization founded by students and faculty from UC Berkeley in collaboration with UCSD and CMU."
  },
  "numParameters": "13B",
  "resources": {
    "canonicalUrl": "https://huggingface.co/lmsys/vicuna-13b-v1.5-16k",
    "downloadUrl": "https://huggingface.co/TheBloke/vicuna-13B-v1.5-16K-GGML",
    "paperUrl": "https://arxiv.org/abs/2306.05685"
  },
  "trainedFor": "chat",
  "arch": "llama",
  "files": {
    "highlighted": {
      "economical": {
        "name": "vicuna-13b-v1.5-16k.ggmlv3.q4_K_S.bin"
      },
      "most_capable": {
        "name": "vicuna-13b-v1.5-16k.ggmlv3.q6_K.bin"
      }
    },
    "all": [
      {
        "name": "vicuna-13b-v1.5-16k.ggmlv3.q4_K_S.bin",
        "url": "https://huggingface.co/TheBloke/vicuna-13B-v1.5-16K-GGML/resolve/main/vicuna-13b-v1.5-16k.ggmlv3.q4_K_S.bin",
        "sizeBytes": 7365545088,
        "quantization": "Q4_K_S",
        "format": "ggml",
        "sha256checksum": "c343200172b677488a7e59a2ef74642b63b2578fde3c976911751181d29ce201",
        "publisher": {
            "name": "TheBloke",
            "socialUrl": "https://twitter.com/TheBlokeAI"
        },
        "respository": "TheBloke/vicuna-13B-v1.5-16K-GGML",
        "repositoryUrl": "https://huggingface.co/TheBloke/vicuna-13B-v1.5-16K-GGML"
      },
      {
        "name": "vicuna-13b-v1.5-16k.ggmlv3.q6_K.bin",
        "url": "https://huggingface.co/TheBloke/vicuna-13B-v1.5-16K-GGML/resolve/main/vicuna-13b-v1.5-16k.ggmlv3.q6_K.bin",
        "sizeBytes": 10678850688,
        "quantization": "Q6_K",
        "format": "ggml",
        "sha256checksum": "949e2003a47552d2931ebce29b94ad59482561a36429fb1c00d13db7feb87fd9",
        "publisher": {
            "name": "TheBloke",
            "socialUrl": "https://twitter.com/TheBlokeAI"
        },
        "respository": "TheBloke/vicuna-13B-v1.5-16K-GGML",
        "repositoryUrl": "https://huggingface.co/TheBloke/vicuna-13B-v1.5-16K-GGML"
      }
    ]
  }
}